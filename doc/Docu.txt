PSM = Peptide Spectrum Matches
# Frage: Warum generiert man nicht mehrere decoy-databases (shuffled, reversed...), damit nicht jeder zweite falsche Eintrag ein decoy ist, sondern jeder dritte, vierte, fünfte....?
1.	Mit Art der Daten vertraut machen, parsen, FDR und q-value berechnen, Pseudo-ROCs zeichnen (Ordner 'Erste Aufgabe')
2.	Richtige Daten mit XL bekommen, Skript aus 'Erste Aufgabe' anwenden, Pseudo-ROCs für XL und nicht-XL zeichnen.
3.	GitHub anlegen
4.	Rang-Spalte hinzufügen und jeweils nur Rang 1 für ROCs benutzen
a.	Vorher (alle Einträge mit entspr. Q-Value, fast method, orange: XL, blue: non-XL): ROC_fast_all.jpg
b.	Nachher (nur Rang-1-Einträge, fast method, orange: XL, blue: non-XL): ROC_fast_rank1only.jpg
c. 	Non-cross-links sehen gleich aus, Cross-links haben gleiche Form aber Anzahl ist bei allen Ranks bis q = 0.05 bei ca. 6000, nur bei Rank 1 nur ca. 4000
5.	Einlesen in lineare ML-Ansätze und ML-package scikit Learn
a. 	LDA: Geht von Normalverteilungen mit unterschiedlichem Erwartungswert und/oder Varianz der einzelnen Scores für jede Klasse aus. Das passt nicht wirklich auf unser Beispiel, da (zumindest die meisten) scores nicht normalverteilt sind (oder?). Ergebnis: lda_compared_to_NuXLscore.png
b. 	Ladder score ist etwas normalverteilt, mit einem deutlich unterschiedlichen Erwartungswert zwischen den wahren und den falschen Trainigsdaten. Nur den zu verwenden macht das Training (natürlich?) nicht besser, wieviel schlechter es ist müsste man noch mehr rausfinden. Ergebnis: lda_of_ladder_score.png
c.	Logistic regression: Trennt ähnlich wie NuXL score. Warum? Wie wird NuXL score zusammengesetzt? Ergebnis: lr_compared_to_NuXLscore.png
d.	SVM: Trennt ähnlich wie NuXL score, wird von percolator benutzt, versucht die Grenze so zu legen, dass der Abstand der Grenze zu Objekten der Klasse maximal ist, ohne zu viele zu wichtige Datenpunkte als Ausreißer zu klassifizieren. Ergebnis: svm_compared_to_NuXLscore.png
6.	Struktur des Notebook verändern, dass man die Module beliebig zusammensetzen kann
7.	Percolator-Algorithmus nachbauen 
Notes:	Seltsames Verhalten der Scores der SVM, siehe Linear_ML.ipynb letzte Zelle. Vielleicht müssen die Scores nochmal transformiert werden? Darum benutze ich allerdings predict_proba bzw. eine lineare SVM, bei der gibt es die Probleme nicht.
	Option 'dual = False' hat es signifikant schneller werden lassen, sodass das Lernen fertig wird (konvergiert) und die Ergebnisse tatsächlich besser sind als der NuXL:score
	Auch die Pseudo-ROC-Kurven wenn man nach dem NuXL:score geht sehen unterschiedlich aus, da im Percolator-Algorithmus zufällig die Hälfte der Decoys entfernt wird.
	Experiment:
		Number of PSMs for q <= 0.01, rank = 1, using rank 1 only = True and classes option = : 5569
		Number of PSMs for q <= 0.01, rank = 1, using rank 1 only = True and classes option = balanced: 5560
		Number of PSMs for q <= 0.01, rank = 1, using rank 1 only = False and classes option = : 5351
		Number of PSMs for q <= 0.01, rank = 1, using rank 1 only = False and classes option = balanced: 5185
		
		Genauere Untersuchung zu den Klassen Optionen mit den Eckwerten von je 10 Ausführungen (q <= 0.01, rank = 1):
		class Option: , max PSMs: 5285, min PSMs: 4413, median PSMs: 5203.0
		class Option: balanced, max PSMs: 5261, min PSMs: 5067, median PSMs: 5179.0

		Genauere Untersuchung dazu, nur Rang 1 fürs Training zu benutzen, zum Scoring aber alle zu nehmen (auch je 10 Ausführungen):
		useRankOneOnly: True, max PSMs: 5111, min PSMs: 4876, median PSMs: 4987.5
		useRankOneOnly: False, max PSMs: 5333, min PSMs: 4320, median PSMs: 4956.0

		Genauere Untersuchung dazu, nur Rang 1 PSMs für Training und Scoring zu benutzen (auch je 10 Ausführungen):
		useRankOneOnly: True, max PSMs: 5669, min PSMs: 5011, median PSMs: 5569.0
		useRankOneOnly: False, max PSMs: 5380, min PSMs: 4364, median PSMs: 5238.0
		Mögliche Gründe: PSMs mit q <= 0.01 aber Rang > 1 werden ausgeschlossen. Es gibt weniger schlechte PSMs im df die man falsch klassifizieren kann?

		Vergleich: mit NuXL:score mit q <= 0.01 findet man 4067 PSMs.
		Bilder jeweils im 'results' Ordner.
8.	Cross-Validation einbauen
